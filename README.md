---

# Hindi Formality Style Transfer

**Bidirectional Text Style Transfer using mT5 and IndicBART**

## ğŸ§  Overview

This project addresses the unique linguistic challenge of **formality style transfer in Hindi**â€”a task that involves converting informal sentences to formal ones and vice versa, without losing the original meaning. We propose a **bidirectional text style transfer model** trained on a custom parallel dataset using **mT5** and **IndicBART**.

> ğŸ”„ Both directions â€” *Formal â¡ï¸ Informal* and *Informal â¡ï¸ Formal* â€” are supported.

The model has demonstrated **better performance** than existing baselines like GPT-2, mBART, and IndicGPT in terms of **BLEU score**, **BERTScore**, and **Perplexity**.

---

## ğŸ§¾ Key Features

* âœ¨ **Bidirectional transfer**: Formal to informal & informal to formal
* ğŸ¤– Fine-tuned **mT5-small** and **AI4Bharat IndicBART** models
* ğŸ“Š Evaluated with **BLEU**, **BERTScore**, and **Perplexity**
* ğŸ”„ Ensemble inference combining both models for improved results
* ğŸ—£ï¸ Focused on Hindi â€” a complex, culturally rich, and low-resource language

---
 
## ğŸ—ï¸ Models Used
ğŸ”¹ **mT5 (Multilingual T5)**
* Pretrained on mC4 corpus

* Encoder-decoder Transformer

* Effective for generalization and semantic preservation

ğŸ”¹ **IndicBART**
* Pretrained on Indic corpora by AI4Bharat

* Strong with morphological and stylistic nuance

* Superior fluency and contextual accuracy

## ğŸ“ Dataset

* **Size**: 50,000 sentence pairs
* **Format**: Parallel corpus of formal and informal Hindi sentences
* **Source**: Created manually and scraped from publicly available Hindi content
* **Usage**: Used for bidirectional training of both models

## ğŸ§  Methodology

### Model Architecture

* **Seq2Seq Transformers**: Both mT5 and IndicBART are encoder-decoder models.
* **Input Format**: `"formal: <sentence>"` or `"informal: <sentence>"`
* **Output Format**: Translated sentence in the desired style

### Training Details

* **Framework**: Hugging Face Transformers
* **Tokenizer**: SentencePiece-based tokenizers for both models
* **Training Epochs**: 5
* **Batch Size**: 16
* **Optimizer**: AdamW
* **Learning Rate Scheduler**: Linear warmup with decay

### Inference Strategy

* **Beam Search**: Used during inference to enhance fluency
* **Ensemble Inference**: Combines predictions from mT5 and IndicBART to improve output quality

### Evaluation Metrics

* **BLEU Score**: 23.0
* **BERTScore**: Precision 0.86, Recall 0.85, F1 0.85
* **Perplexity**: 8.25

## ğŸ“Š Results

| Model         | BLEU  | BERTScore F1 | Perplexity |
| ------------- | ----- | ------------ | ---------- |
| **mT5**       | 23.31 | 0.85         | 8.25       |
| **IndicBART** | 17.84 | 0.81         | 5.36       |
| **Ensemble**  | 21.65 | 0.84         | 6.20       |
| GPT-2         | 0.26  | 0.60         | 3.13       |
| IndicGPT      | 20.01 | 0.63         | 41.77      |
| mBART         | 8.91  | 0.77         | 15.07      |


## ğŸ”§ Installation

```bash
git clone https://github.com/Varalakshmikannuru/hindi-formality-transfer.git
cd hindi-formality-transfer
pip install -r requirements.txt
```

## ğŸƒâ€â™€ï¸ Running the Project

### Training

```bash
python train.py --model mt5 --epochs 5 --batch_size 16
python train.py --model indicbart --epochs 5 --batch_size 16
```

### Inference

```bash
python inference.py --input "formal: à¤•à¥à¤¯à¤¾ à¤†à¤ª à¤ à¥€à¤• à¤¹à¥ˆà¤‚?" --model ensemble
```

## ğŸ§ª Folder Structure

```
hindi-formality-transfer/
â”‚
â”œâ”€â”€ data/                     # Training and evaluation datasets
â”œâ”€â”€ models/                   # Saved model checkpoints
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py              # Training script
â”‚   â”œâ”€â”€ inference.py          # Inference script
â”‚   â”œâ”€â”€ utils.py              # Utility functions
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ metrics.py            # Evaluation metrics
â”‚   â””â”€â”€ results/              # Result outputs
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## âœï¸ Author

**Varalakshmi Kannuru**
Final Year B.Tech Student | AI/ML Enthusiast
ğŸ“« [Varalakshmikannuru](https://github.com/Varalakshmikannuru)
