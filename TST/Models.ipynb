{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1apVMmsKH2xj8nuwMCe9l7SV2yWeuwHD6","authorship_tag":"ABX9TyOGbadfEbr7amksfnT7C/xg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Lf8-7n4BWeZP"},"outputs":[],"source":["pip install torch transformers"]},{"cell_type":"code","source":["pip install datasets"],"metadata":{"id":"TTucOKgJWroj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Formality data ==> Bi-directional Formality data"],"metadata":{"id":"KkLq-mHHycoR"}},{"cell_type":"code","source":["import pandas as pd\n","from datasets import Dataset\n","\n","# Load dataset (Ensure CSV has 'informal' and 'formal' columns)\n","df = pd.read_csv(\"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/Formality_data.csv\").reset_index(drop=True)\n","\n","# Verify dataset columns\n","assert 'informal' in df.columns and 'formal' in df.columns, \"Dataset must contain 'informal' and 'formal' columns\"\n","\n","# Remove any rows with missing values\n","df = df.dropna(subset=['informal', 'formal'])\n","\n","# Prepare bidirectional samples\n","def create_bidirectional_dataset(df):\n","    \"\"\"Generates bidirectional pairs from the original dataset.\"\"\"\n","    bidirectional_data = []\n","\n","    for informal, formal in zip(df[\"informal\"], df[\"formal\"]):\n","        # Informal → Formal\n","        bidirectional_data.append({\n","            \"input\": \"informal to formal: \" + informal,\n","            \"target\": formal\n","        })\n","\n","        # Formal → Informal\n","        bidirectional_data.append({\n","            \"input\": \"formal to informal: \" + formal,\n","            \"target\": informal\n","        })\n","\n","    return Dataset.from_list(bidirectional_data)\n","\n","# Generate the bidirectional dataset\n","bidirectional_dataset = create_bidirectional_dataset(df)\n","\n","# Save the bidirectional dataset for training\n","bidirectional_dataset.to_csv(\"/content/drive/MyDrive/TST/bidirectional_dataset.csv\", index=False)"],"metadata":{"id":"98VVsVoUyZQ-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# mT5 model training"],"metadata":{"id":"Fd3aTGl7Xx_N"}},{"cell_type":"code","source":["import torch\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n","from torch.optim import AdamW\n","from datasets import load_dataset\n","\n","\n","# Check GPU availability\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# Load preprocessed bidirectional dataset (Ensure CSV has 'input' and 'target' columns)\n","dataset_path = '/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/bidirectional_dataset.csv'\n","dataset = load_dataset('csv', data_files={'train': dataset_path})\n","\n","# Verify dataset structure\n","print(dataset)\n","\n","# Load mT5 Tokenizer\n","tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-small\")\n","\n","# Preprocessing function for tokenization\n","def preprocess_function(examples):\n","    \"\"\"Tokenize inputs and targets with padding/truncation.\"\"\"\n","    if 'input' not in examples or 'target' not in examples:\n","        raise ValueError(\"Dataset must contain 'input' and 'target' columns.\")\n","\n","    model_inputs = tokenizer(\n","        examples[\"input\"], max_length=128, truncation=True, padding=\"max_length\"\n","    )\n","\n","    labels = tokenizer(\n","        examples[\"target\"], max_length=128, truncation=True, padding=\"max_length\"\n","    ).input_ids\n","\n","    # Replace padding tokens with -100 for loss masking\n","    labels = [[-100 if token == tokenizer.pad_token_id else token for token in label] for label in labels]\n","\n","    model_inputs[\"labels\"] = labels\n","    return model_inputs\n","\n","# Apply preprocessing\n","tokenized_dataset = dataset['train'].map(preprocess_function, batched=True)\n","\n","# Split into train and eval sets\n","dataset = tokenized_dataset.train_test_split(test_size=0.1)\n","train_dataset = dataset[\"train\"]\n","eval_dataset = dataset[\"test\"]\n","\n","# Load Model and Move to Device\n","model = T5ForConditionalGeneration.from_pretrained(\"google/mt5-small\").to(device)\n","\n","# Training Arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=3,  # Increased number of epochs\n","    learning_rate=3e-5,  # Adjusted learning rate\n","    logging_dir=\"./logs\",\n","    save_total_limit=2,\n",")\n","\n","# Advanced Optimizer\n","optimizer = AdamW(model.parameters(), lr=3e-5)\n","\n","# Trainer Setup\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    optimizers=(optimizer, None),  # Custom optimizer\n",")\n","\n","# Train the Model\n","print(\"\\n🚀 Starting fine-tuning...\")\n","trainer.train()\n","\n","# Save the Final Model\n","model.save_pretrained(\"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/mt5_model\")\n","tokenizer.save_pretrained(\"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/mt5_model\")\n","\n","print(\"\\n Model saved successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRQoxSAn1yYl","executionInfo":{"status":"ok","timestamp":1745867986236,"user_tz":-330,"elapsed":97,"user":{"displayName":"Vasavi Kannuru","userId":"01253912739111961725"}},"outputId":"e8a72bbc-c34e-4de4-d640-55963561e4e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","DatasetDict({\n","    train: Dataset({\n","        features: ['input', 'target'],\n","        num_rows: 47036\n","    })\n","})\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-1-20c55568e28e>:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\n","🚀 Starting fine-tuning...\n","wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","wandb: Currently logged in as: varalakshmikannuru1111 (varalakshmikannuru-srkr-engineering-college) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n","Tracking run with wandb version 0.19.8\n","Run data is saved locally in /content/wandb/run-20250404_070454-yfcx0tui\n","Syncing run ./results to Weights & Biases (docs)\n","View project at https://wandb.ai/varalakshmikannuru-srkr-engineering-college/huggingface\n","View run at https://wandb.ai/varalakshmikannuru-srkr-engineering-college/huggingface/runs/yfcx0tui\n","Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"," \n"," [ 5293/15876 42:37 < 1:25:16, 2.07 it/s, Epoch 3/3]\n","\n","Epoch\tTraining Loss\tValidation Loss\n","1\t1.278200\t0.989306\n","2\t1.261900\t0.950524\n","3\t1.237300\t0.943257\n","\n","Model saved successfully!\n"]}]},{"cell_type":"code","source":["# Inference Functions for Both Directions\n","def generate_sentence(input_text, direction=\"informal_to_formal\"):\n","    \"\"\"\n","    Generates a sentence in the specified direction:\n","    - \"informal_to_formal\" → Converts informal to formal\n","    - \"formal_to_informal\" → Converts formal to informal\n","    \"\"\"\n","    model.eval()\n","\n","    prompt = f\"{'informal to formal' if direction == 'informal_to_formal' else 'formal to informal'}: {input_text}\"\n","\n","    # Tokenize and move to device\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n","\n","    # Generate\n","    with torch.no_grad():\n","        output_ids = model.generate(input_ids, max_length=128, num_beams=5, early_stopping=True)\n","\n","    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","  # Example Testing\n","print(\"\\n🚀 Testing the Model\")\n","print(\"Informal → Formal:\", generate_sentence(\"तू कहाँ जा रहा है?\", direction=\"informal_to_formal\"))\n","print(\"Formal → Informal:\", generate_sentence(\"आप कहाँ जा रहे हैं?\", direction=\"formal_to_informal\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZmzYenifW0ha","executionInfo":{"status":"ok","timestamp":1745658599193,"user_tz":-330,"elapsed":27,"user":{"displayName":"Vasavi Kannuru","userId":"01253912739111961725"}},"outputId":"2fc81670-826e-4f47-b87f-825a04dcfed4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Testing the Model\n","Informal → Formal: आप कहाँ जा रहे हैं?\n","Formal → Informal: तुम कहाँ जा रहे हो?\n"]}]},{"cell_type":"markdown","source":["## mT5 model inference"],"metadata":{"id":"OwsyZkhfcAXJ"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","import torch\n","\n","# Replace with your model's path or checkpoint name\n","model_path = \"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/mt5_model\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Batch inference for multiple sentences\n","def batch_generate(sentences, direction=\"informal_to_formal\", max_length=128, num_beams=5):\n","    \"\"\"\n","    Generates sentences in batch:\n","    - direction: \"informal_to_formal\" or \"formal_to_informal\"\n","    - max_length: maximum length of the output sentences\n","    - num_beams: number of beams for beam search\n","    \"\"\"\n","    model.eval()\n","\n","    # Add direction prefix to each sentence\n","    prompts = [\n","        f\"{'informal to formal' if direction == 'informal_to_formal' else 'formal to informal'}: {sentence}\"\n","        for sentence in sentences\n","    ]\n","\n","    # Tokenize the batch\n","    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device)\n","\n","    # Generate predictions\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            inputs.input_ids,\n","            max_length=max_length,\n","            num_beams=num_beams,\n","            early_stopping=True\n","        )\n","\n","    # Decode predictions\n","    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HADZhy5nXFU4","executionInfo":{"status":"ok","timestamp":1745815177638,"user_tz":-330,"elapsed":28782,"user":{"displayName":"Vasavi Kannuru","userId":"01253912739111961725"}},"outputId":"621e872e-9414-4847-81ee-74a9c6ec968c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n","/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Example testing with multiple sentences\n","informal_sentences = [\n","    \"खाना खा।\",\n","    \"बैठ जा।\",\n","    \"जल्दी कर।\",\n","    \"खाना मस्त था, थैंक्स!\",\n","    \"इस होटल की सर्विस बढ़िया है।\",\n","    \"ऑफिस में आ जा, भाई!\",\n","    \"फटाफट पेपर दिखा दे।\",\n","    \"नई जॉब के लिए एप्लाई कर रहा क्या?\",\n","    \"पेपर की तैयारी हो गई क्या?\",\n","    \"तेरी पढ़ाई तो टॉप लेवल की है।\",\n","    \"रिजल्ट चेक कर ले।\",\n","    \"तेरी शादी में आके बहुत मज़ा आया।\",\n","    \"शादी में आएगा ना?\",\n","    \"टाइम पे काम कर भाई।\",\n","    \"यार मीटिंग में टाइम से आ जाना।\",\n","    \"तेरी तबियत ठीक चल रही है।\",\n","    \"वो मूवी देखी क्या?\",\n","    \"तेरी फेवरेट मूवी कौन सी है?\",\n","    \"तेरे घरवालों को दिवाली मुबारक!\",\n","    \"स्कूल में सबका स्वागत है।\",\n","    \"तेरा स्कूल बहुत अच्छा है।\",\n","    \"सिलेबस फॉलो कर ले।\",\n","    \"तेरी पढ़ाई सही चल रही है।\",\n","    \"पेपर क्लियर किया क्या?\",\n","    \"तू उससे प्यार करता है क्या?\",\n","    \"तेरी यारी लाजवाब है।\",\n","    \"तेरा प्यार सच्चा लगता है।\",\n","]\n","\n","formal_sentences = [\n","    \"खाना खाइए।\",\n","    \"कृपया बैठ जाइए।\",\n","    \"कृपया शीघ्र करें।\",\n","    \"भोजन अत्यंत स्वादिष्ट था, धन्यवाद।\",\n","    \"आपका व्यंजन बहुत लजीज था।\",\n","    \"क्या आप भोजन का स्वाद पसंद कर रहे हैं?\",\n","    \"कृपया अपने दस्तावेज़ प्रस्तुत करें।\",\n","    \"आपकी नौकरी में तरक्की हुई है।\",\n","    \"क्या आप नई नौकरी के लिए आवेदन कर रहे हैं?\",\n","    \"आपकी शिक्षा अत्यंत प्रशंसनीय है।\",\n","    \"क्या आपने अपनी परीक्षा की तैयारी पूरी कर ली?\",\n","    \"आपकी शिक्षा का स्तर अत्यंत उच्च है।\",\n","    \"कृपया परीक्षा परिणाम देखें।\",\n","    \"आपका विवाह समारोह बहुत भव्य था।\",\n","    \"क्या आप विवाह में सम्मिलित होंगे?\",\n","    \"आपके सहयोग के लिए धन्यवाद।\",\n","    \"कृपया समय पर कार्य करें।\",\n","    \"आपकी मेहनत अत्यंत सराहनीय है।\",\n","    \"कृपया मीटिंग में समय पर पहुंचें।\",\n","    \"कृपया नियमित रूप से व्यायाम करें।\",\n","    \"क्या आपने वह फिल्म देखी है?\",\n","    \"आपकी पसंदीदा फिल्म कौन सी है?\",\n","    \"त्योहार की हार्दिक शुभकामनाएँ।\",\n","    \"आपके परिवार को दीपावली की बधाई।\",\n","    \"क्या आप होली खेलेंगे?\",\n","    \"विद्यालय में सभी छात्रों का स्वागत है।\",\n","    \"महाविद्यालय का वातावरण शांतिपूर्ण है।\",\n","    \"आपकी कॉलेज की पढ़ाई सराहनीय है।\",\n","    \"क्या आप परीक्षा में उत्तीर्ण हुए हैं?\",\n","    \"क्या आप उससे प्रेम करते हैं?\",\n","    \"आपकी दोस्ती सराहनीय है।\",\n","    \"आपके प्रेम में सच्चाई झलकती है।\",\n","]\n","\n","print(\"=== mt5 model output ===\")\n","# Batch inference\n","print(\"\\n🚀 Informal → Formal (Batch)\")\n","formal_outputs = batch_generate(informal_sentences, direction=\"informal_to_formal\")\n","for informal, formal in zip(informal_sentences, formal_outputs):\n","    print(f\"Informal: {informal}\")\n","    print(f\"Formal: {formal}\\n\")\n","\n","print(\"\\n🚀 Formal → Informal (Batch)\")\n","informal_outputs = batch_generate(formal_sentences, direction=\"formal_to_informal\")\n","for formal, informal in zip(formal_sentences, informal_outputs):\n","    print(f\"Formal: {formal}\")\n","    print(f\"Informal: {informal}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epAL6N4OXM7k","executionInfo":{"status":"ok","timestamp":1745809979492,"user_tz":-330,"elapsed":126102,"user":{"displayName":"Vasavi Kannuru","userId":"01253912739111961725"}},"outputId":"e07e32b5-a5d5-4d57-a082-0f0f9011b2f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== mt5 model output ===\n","\n","🚀 Informal → Formal (Batch)\n","Informal: खाना खा।\n","Formal: कृपया खाना खाइए।\n","\n","Informal: बैठ जा।\n","Formal: कृपया बैठ जाइए।\n","\n","Informal: जल्दी कर।\n","Formal: कृपया जल्दी करें।\n","\n","Informal: खाना मस्त था, थैंक्स!\n","Formal: यह खाना बहुत अच्छा था।\n","\n","Informal: इस होटल की सर्विस बढ़िया है।\n","Formal: इस होटल की सर्विस बहुत सराहनीय है।\n","\n","Informal: ऑफिस में आ जा, भाई!\n","Formal: कृपया ऑफिस में आ जाइए।\n","\n","Informal: फटाफट पेपर दिखा दे।\n","Formal: कृपया मुझे फटाफट पेपर दिखा दीजिए।\n","\n","Informal: नई जॉब के लिए एप्लाई कर रहा क्या?\n","Formal: क्या आप नई जॉब के लिए एप्लाई कर रहे हैं?\n","\n","Informal: पेपर की तैयारी हो गई क्या?\n","Formal: क्या इस पेपर की तैयारी हो गई?\n","\n","Informal: तेरी पढ़ाई तो टॉप लेवल की है।\n","Formal: आपकी पढ़ाई तो टॉप लेवल की है।\n","\n","Informal: रिजल्ट चेक कर ले।\n","Formal: कृपया रिजल्ट चेक करें।\n","\n","Informal: तेरी शादी में आके बहुत मज़ा आया।\n","Formal: आपकी शादी में आके बहुत मज़ा आया।\n","\n","Informal: शादी में आएगा ना?\n","Formal: क्या आप शादी में आएंगे?\n","\n","Informal: टाइम पे काम कर भाई।\n","Formal: कृपया टाइम पे काम करें।\n","\n","Informal: यार मीटिंग में टाइम से आ जाना।\n","Formal: कृपया वो मीटिंग में टाइम से आ जाइए।\n","\n","Informal: तेरी तबियत ठीक चल रही है।\n","Formal: आपकी तबियत ठीक चल रही है।\n","\n","Informal: वो मूवी देखी क्या?\n","Formal: क्या आपने वो फिल्म देखी?\n","\n","Informal: तेरी फेवरेट मूवी कौन सी है?\n","Formal: आपकी पसंदीदा फिल्म कौन सी है?\n","\n","Informal: तेरे घरवालों को दिवाली मुबारक!\n","Formal: आपके घरवालों को दिवाली मुबारक!\n","\n","Informal: स्कूल में सबका स्वागत है।\n","Formal: विद्यालय में छात्रों के लिए सबका स्वागत है।\n","\n","Informal: तेरा स्कूल बहुत अच्छा है।\n","Formal: आपका वो स्कूल बहुत अच्छा है।\n","\n","Informal: सिलेबस फॉलो कर ले।\n","Formal: कृपया अपनी सिलेबस फॉलो करें।\n","\n","Informal: तेरी पढ़ाई सही चल रही है।\n","Formal: आपकी तेरी पढ़ाई बहुत सराहनीय है।\n","\n","Informal: पेपर क्लियर किया क्या?\n","Formal: क्या आपने पेपर क्लियर किया?\n","\n","Informal: तू उससे प्यार करता है क्या?\n","Formal: क्या आप वोसे प्यार करते हैं?\n","\n","Informal: तेरी यारी लाजवाब है।\n","Formal: आपकी तेरी सराहनीय है।\n","\n","Informal: तेरा प्यार सच्चा लगता है।\n","Formal: आपका प्रेम सच्चा लगता है।\n","\n","\n","🚀 Formal → Informal (Batch)\n","Formal: खाना खाइए।\n","Informal: खाना खाइए।\n","\n","Formal: कृपया बैठ जाइए।\n","Informal: बैठ।\n","\n","Formal: कृपया शीघ्र करें।\n","Informal: शीघ्र कर।\n","\n","Formal: भोजन अत्यंत स्वादिष्ट था, धन्यवाद।\n","Informal: भाई, भोजन बहुत अच्छा था।\n","\n","Formal: आपका व्यंजन बहुत लजीज था।\n","Informal: तेरा व्यंजन बहुत अच्छा था।\n","\n","Formal: क्या आप भोजन का स्वाद पसंद कर रहे हैं?\n","Informal: भोजन का स्वाद पसंद कर रहे हैं क्या?\n","\n","Formal: कृपया अपने दस्तावेज़ प्रस्तुत करें।\n","Informal: अपने दस्तावेज़ प्रस्तुत कर।\n","\n","Formal: आपकी नौकरी में तरक्की हुई है।\n","Informal: तेरी नौकरी में तरक्की हुई है।\n","\n","Formal: क्या आप नई नौकरी के लिए आवेदन कर रहे हैं?\n","Informal: तुम नई नौकरी के लिए आवेदन कर रहे हो?\n","\n","Formal: आपकी शिक्षा अत्यंत प्रशंसनीय है।\n","Informal: तेरी शिक्षा बहुत बढ़िया है।\n","\n","Formal: क्या आपने अपनी परीक्षा की तैयारी पूरी कर ली?\n","Informal: क्या तूने अपनी परीक्षा की तैयारी कर ली?\n","\n","Formal: आपकी शिक्षा का स्तर अत्यंत उच्च है।\n","Informal: तेरी शिक्षा का स्तर बहुत बढ़िया है।\n","\n","Formal: कृपया परीक्षा परिणाम देखें।\n","Informal: परीक्षा परिणाम देख।\n","\n","Formal: आपका विवाह समारोह बहुत भव्य था।\n","Informal: तेरा विवाह समारोह बहुत अच्छा था।\n","\n","Formal: क्या आप विवाह में सम्मिलित होंगे?\n","Informal: क्या तू विवाह में हिस्सा लेगा?\n","\n","Formal: आपके सहयोग के लिए धन्यवाद।\n","Informal: तेरे सहयोग के लिए धन्यवाद।\n","\n","Formal: कृपया समय पर कार्य करें।\n","Informal: समय पर काम कर।\n","\n","Formal: आपकी मेहनत अत्यंत सराहनीय है।\n","Informal: तेरी मेहनत बहुत सराहनीय है।\n","\n","Formal: कृपया मीटिंग में समय पर पहुंचें।\n","Informal: भाई, मीटिंग में टाइम पर पहुंच।\n","\n","Formal: कृपया नियमित रूप से व्यायाम करें।\n","Informal: नियमित रूप से व्यायाम कर।\n","\n","Formal: क्या आपने वह फिल्म देखी है?\n","Informal: क्या तूने उस फिल्म देखी है?\n","\n","Formal: आपकी पसंदीदा फिल्म कौन सी है?\n","Informal: तेरी फेवरेट फिल्म कौन सी है?\n","\n","Formal: त्योहार की हार्दिक शुभकामनाएँ।\n","Informal: त्योहार की शुभकामनाएँ।\n","\n","Formal: आपके परिवार को दीपावली की बधाई।\n","Informal: तेरे परिवार को दीपावली की बधाई।\n","\n","Formal: क्या आप होली खेलेंगे?\n","Informal: होली खेलेंगे क्या?\n","\n","Formal: विद्यालय में सभी छात्रों का स्वागत है।\n","Informal: स्कूल में सभी छात्रों का स्वागत है।\n","\n","Formal: महाविद्यालय का वातावरण शांतिपूर्ण है।\n","Informal: कॉलेज का वातावरण शांतिपूर्ण है।\n","\n","Formal: आपकी कॉलेज की पढ़ाई सराहनीय है।\n","Informal: तेरी कॉलेज की पढ़ाई बढ़िया है।\n","\n","Formal: क्या आप परीक्षा में उत्तीर्ण हुए हैं?\n","Informal: भाई, परीक्षा में हिस्सा ले।\n","\n","Formal: क्या आप उससे प्रेम करते हैं?\n","Informal: क्या तू उससे प्यार करता है?\n","\n","Formal: आपकी दोस्ती सराहनीय है।\n","Informal: तेरी दोस्ती बहुत बढ़िया है।\n","\n","Formal: आपके प्रेम में सच्चाई झलकती है।\n","Informal: तेरे प्यार में सच्चाई झलकती है।\n","\n"]}]},{"cell_type":"markdown","source":["## mT5 performance evaluation"],"metadata":{"id":"nexD2UugX4fQ"}},{"cell_type":"code","source":["pip install evaluate sacrebleu rouge_score bert_score"],"metadata":{"id":"18kIGLf5XZEl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, GPT2LMHeadModel, GPT2Tokenizer\n","import pandas as pd\n","import evaluate\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# Load trained T5 model and tokenizer\n","model_path = \"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/mt5_finetuned2_model\"  # Update model path\n","tokenizer = T5Tokenizer.from_pretrained(model_path)\n","model = T5ForConditionalGeneration.from_pretrained(model_path).to(device)\n","\n","# Load test dataset\n","test_data = pd.read_csv(\"/content/drive/MyDrive/TST/test.csv\")\n","# test_data = df[:500]\n","\n","# Load Evaluation Metrics\n","bleu_metric = evaluate.load(\"sacrebleu\")\n","rouge_metric = evaluate.load(\"rouge\")\n","bertscore_metric = evaluate.load(\"bertscore\")\n","\n","# Load GPT-2 for Perplexity Calculation (Fluency)\n","gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n","\n","# Function to generate formal sentences using T5\n","def generate_formal_sentence(informal_text):\n","    input_text = \"informal to formal: \" + informal_text\n","    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","\n","    with torch.no_grad():\n","        output_ids = model.generate(input_ids,\n","                                    max_length=128,\n","                                    num_beams=5,\n","                                    repetition_penalty=2.0)  # Better output quality\n","\n","    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","# Function to calculate Perplexity (Lower = Better Fluency)\n","def calculate_perplexity(sentence):\n","    inputs = gpt2_tokenizer(sentence, return_tensors=\"pt\").input_ids.to(device)\n","    with torch.no_grad():\n","        loss = gpt2_model(inputs, labels=inputs).loss\n","    return torch.exp(loss).item()\n","\n","# Evaluate model\n","correct_predictions = 0\n","total_samples = len(test_data)\n","predictions, references, perplexities = [], [], []\n","\n","for i, row in test_data.iterrows():\n","    informal = row[\"informal\"]\n","    formal = row[\"formal\"]\n","\n","    predicted_formal = generate_formal_sentence(informal)\n","\n","    predictions.append(predicted_formal)\n","    references.append([formal])  # BLEU expects a list of references\n","    perplexities.append(calculate_perplexity(predicted_formal))  # Fluency score\n","\n","    if predicted_formal.strip() == formal.strip():\n","        correct_predictions += 1\n","\n","# Compute evaluation metrics\n","accuracy = correct_predictions / total_samples * 100\n","bleu_score = bleu_metric.compute(predictions=predictions, references=references)[\"score\"]\n","rouge_scores = rouge_metric.compute(predictions=predictions, references=[ref[0] for ref in references])\n","bertscore_results = bertscore_metric.compute(predictions=predictions, references=[ref[0] for ref in references], lang=\"hi\")\n","avg_perplexity = sum(perplexities) / len(perplexities)\n","\n","# Print results\n","print(\"\\n===== mT5 Evaluation Results on New Format (input → target) =====\")\n","print(f\"🔹 Accuracy: {accuracy:.2f}%\")\n","print(f\"🔹 BLEU Score: {bleu_score:.2f}\")\n","print(f\"🔹 ROUGE Scores: {rouge_scores}\")\n","print(f\"🔹 BERTScore Precision: {sum(bertscore_results['precision']) / len(bertscore_results['precision']):.2f}\")\n","print(f\"🔹 BERTScore Recall: {sum(bertscore_results['recall']) / len(bertscore_results['recall']):.2f}\")\n","print(f\"🔹 BERTScore F1: {sum(bertscore_results['f1']) / len(bertscore_results['f1']):.2f}\")\n","print(f\"🔹 Avg Perplexity: {avg_perplexity:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OyEWjJAxXfBA","executionInfo":{"status":"ok","timestamp":1745658719026,"user_tz":-330,"elapsed":34,"user":{"displayName":"Vasavi Kannuru","userId":"01253912739111961725"}},"outputId":"10bfbc6b-77e6-45cc-9c36-24f32215f2f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","\n","===== mT5 Evaluation Results (input → target) =====\n","🔹 Accuracy: 10.05%\n","🔹 BLEU Score: 23.31\n","🔹 ROUGE Scores: {'rouge1': np.float64(0.0), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.0), 'rougeLsum': np.float64(0.0)}\n","🔹 BERTScore Precision: 0.85\n","🔹 BERTScore Recall: 0.85\n","🔹 BERTScore F1: 0.85\n","🔹 Avg Perplexity: 8.25\n"]}]},{"cell_type":"markdown","source":["# IndicBart model training"],"metadata":{"id":"6ulWwYGeX98H"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n","from datasets import load_dataset\n","from huggingface_hub import login\n","\n","# Optional: Authenticate with Hugging Face\n","login()\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# Load updated dataset or continue with the same one\n","dataset_path = '/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/bidirectional_dataset.csv'\n","dataset = load_dataset('csv', data_files={'train': dataset_path})\n","\n","# Load tokenizer and model from the previously saved checkpoint\n","checkpoint_path = \"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/IndicBART_model\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n","model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_path).to(device)\n","\n","# Tokenization function\n","def preprocess_function(examples):\n","    inputs = tokenizer(\n","        examples[\"input\"], max_length=128, truncation=True, padding=\"max_length\"\n","    )\n","    labels = tokenizer(\n","        examples[\"target\"], max_length=128, truncation=True, padding=\"max_length\"\n","    ).input_ids\n","\n","    labels = [[-100 if token == tokenizer.pad_token_id else token for token in label] for label in labels]\n","    inputs[\"labels\"] = labels\n","    return inputs\n","\n","# Tokenize and split dataset\n","tokenized_dataset = dataset['train'].map(preprocess_function, batched=True)\n","dataset_split = tokenized_dataset.train_test_split(test_size=0.1)\n","train_dataset = dataset_split[\"train\"]\n","eval_dataset = dataset_split[\"test\"]\n","\n","# Define updated training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results_continue\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=2,  # Add more epochs\n","    logging_dir=\"./logs_continue\",\n","    save_total_limit=2,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n",")\n","\n","# Data collator and trainer\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")\n","\n","# Continue training\n","trainer.train()\n","\n","# Save the updated model after additional fine-tuning\n","output_path = \"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/IndicBART_finetune\"\n","model.save_pretrained(output_path)\n","tokenizer.save_pretrained(output_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cw81U4CrXilC","executionInfo":{"status":"ok","timestamp":1745659122723,"user_tz":-330,"elapsed":39,"user":{"displayName":"Vasavi Kannuru","userId":"01253912739111961725"}},"outputId":"7f4afaee-e269-4139-a0ac-5c9dc478eebf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-3-20c46716fdef>:58: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","\n","wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","wandb: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n","wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","wandb: No netrc file found, creating one.\n","wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","wandb: Currently logged in as: varalakshmikannuru1111 (varalakshmikannuru-srkr-engineering-college) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n","Tracking run with wandb version 0.19.9\n","Run data is saved locally in /content/wandb/run-20250410_062027-7z8zro2b\n","Syncing run ./results_continue to Weights & Biases (docs)\n","View project at https://wandb.ai/varalakshmikannuru-srkr-engineering-college/huggingface\n","View run at https://wandb.ai/varalakshmikannuru-srkr-engineering-college/huggingface/runs/7z8zro2b\n"," \n"," [10584/10584 2:35:20, Epoch 3/3]\n","\n","Epoch\tTraining Loss\tValidation Loss\n","1\t    0.886800\t    0.743933\n","2\t    0.856500\t    0.735782\n","3\t    0.839000\t    0.721388\n","\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","('/content/drive/MyDrive/TST/IndicBART_model/tokenizer_config.json',\n"," '/content/drive/MyDrive/TST/IndicBART_model/special_tokens_map.json',\n"," '/content/drive/MyDrive/TST/IndicBART_model/spiece.model',\n"," '/content/drive/MyDrive/TST/IndicBART_model/added_tokens.json',\n"," '/content/drive/MyDrive/TST/IndicBART_model/tokenizer.json')\n"]}]},{"cell_type":"code","source":["# Inference Functions for Both Directions\n","def generate_sentence(input_text, direction=\"informal_to_formal\"):\n","    \"\"\"\n","    Generates a sentence in the specified direction:\n","    - \"informal_to_formal\" → Converts informal to formal\n","    - \"formal_to_informal\" → Converts formal to informal\n","    \"\"\"\n","    model.eval()\n","\n","    prompt = f\"{'informal to formal' if direction == 'informal_to_formal' else 'formal to informal'}: {input_text}\"\n","\n","    # Tokenize and move to device\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n","\n","    # Generate\n","    with torch.no_grad():\n","        output_ids = model.generate(input_ids, max_length=128, num_beams=5, early_stopping=True)\n","\n","    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","  # Example Testing\n","print(\"\\n🚀 Testing the Model\")\n","print(\"Informal → Formal:\", generate_sentence(\"तू कहाँ जा रहा है?\", direction=\"informal_to_formal\"))\n","print(\"Formal → Informal:\", generate_sentence(\"आप कहाँ जा रहे हैं?\", direction=\"formal_to_informal\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aztXAyVYYRdY","executionInfo":{"status":"ok","timestamp":1745659157423,"user_tz":-330,"elapsed":20,"user":{"displayName":"Vasavi Kannuru","userId":"01253912739111961725"}},"outputId":"3b594176-ba40-4924-a846-5bb57726bedc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Testing the Model\n","Informal → Formal: आप कहाँ जा रहे हैं?\n","Formal → Informal: तू कहाँ जा रहा है?\n"]}]},{"cell_type":"markdown","source":["## IndicBART model inference"],"metadata":{"id":"AO12sKKzcHBd"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","# Load the IndicBART model and tokenizer\n","checkpoint_path = \"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/IndicBART_model\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n","model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_path)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Batch inference for multiple sentences (cleaned version)\n","def batch_generate_indicbart(sentences, direction=\"informal_to_formal\", max_length=128, num_beams=5):\n","    \"\"\"\n","    Generates sentences in batch for IndicBART model:\n","    Ensures only the first sentence is kept if multiple are generated.\n","    \"\"\"\n","    model.eval()\n","\n","    # Add direction prefix to each sentence\n","    prompts = [\n","        f\"{'informal to formal' if direction == 'informal_to_formal' else 'formal to informal'}: {sentence}\"\n","        for sentence in sentences\n","    ]\n","\n","    # Tokenize the batch\n","    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device)\n","\n","    # Generate predictions\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            inputs.input_ids,\n","            max_length=max_length,\n","            num_beams=num_beams,\n","            early_stopping=True\n","        )\n","\n","    # Decode and keep only the first sentence\n","    decoded_outputs = []\n","    for output in outputs:\n","        text = tokenizer.decode(output, skip_special_tokens=True)\n","        # Split by '।' (Hindi full stop) and take the first non-empty part\n","        first_sentence = text.split('।')[0].strip()\n","        if first_sentence:  # Add '।' back if needed\n","            first_sentence += '।'\n","        decoded_outputs.append(first_sentence)\n","\n","    return decoded_outputs\n"],"metadata":{"id":"chKUFgNkio4P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example testing with multiple sentences\n","informal_sentences = [\n","    \"खाना खा।\",\n","    \"बैठ जा।\",\n","    \"जल्दी कर।\",\n","    \"खाना मस्त था, थैंक्स!\",\n","    \"इस होटल की सर्विस बढ़िया है।\",\n","    \"ऑफिस में आ जा, भाई!\",\n","    \"फटाफट पेपर दिखा दे।\",\n","    \"नई जॉब के लिए एप्लाई कर रहा क्या?\",\n","    \"तेरी पढ़ाई तो टॉप लेवल की है।\",\n","    \"रिजल्ट चेक कर ले।\",\n","    \"शादी में आएगा ना?\",\n","    \"टाइम पे काम कर भाई।\",\n","    \"यार मीटिंग में टाइम से आ जाना।\",\n","    \"तेरी तबियत ठीक चल रही है।\",\n","    \"वो मूवी देखी क्या?\",\n","    \"तेरी फेवरेट मूवी कौन सी है?\",\n","    \"तेरे घरवालों को दिवाली मुबारक!\",\n","    \"स्कूल में सबका स्वागत है।\",\n","    \"तेरा स्कूल बहुत अच्छा है।\",\n","    \"तेरी पढ़ाई सही चल रही है।\",\n","    \"पेपर क्लियर किया क्या?\",\n","    \"तू उससे प्यार करता है क्या?\",\n","    \"तेरा प्यार सच्चा लगता है।\",\n","]\n","\n","formal_sentences = [\n","    \"खाना खाइए।\",\n","    \"कृपया बैठ जाइए।\",\n","    \"कृपया शीघ्र करें।\",\n","    \"भोजन अत्यंत स्वादिष्ट था, धन्यवाद।\",\n","    \"क्या आप भोजन का स्वाद पसंद कर रहे हैं?\",\n","    \"कृपया अपने दस्तावेज़ प्रस्तुत करें।\",\n","    \"आपकी नौकरी में तरक्की हुई है।\",\n","    \"क्या आप नई नौकरी के लिए आवेदन कर रहे हैं?\",\n","    \"आपकी शिक्षा का स्तर अत्यंत उच्च है।\",\n","    \"कृपया परीक्षा परिणाम देखें।\",\n","    \"आपका विवाह समारोह बहुत भव्य था।\",\n","    \"क्या आप विवाह में सम्मिलित होंगे?\",\n","    \"आपके सहयोग के लिए धन्यवाद।\",\n","    \"कृपया समय पर कार्य करें।\",\n","    \"आपकी मेहनत अत्यंत सराहनीय है।\",\n","    \"कृपया मीटिंग में समय पर पहुंचें।\",\n","    \"कृपया नियमित रूप से व्यायाम करें।\",\n","    \"क्या आपने वह फिल्म देखी है?\",\n","    \"आपकी पसंदीदा फिल्म कौन सी है?\",\n","    \"त्योहार की हार्दिक शुभकामनाएँ।\",\n","    \"आपके परिवार को दीपावली की बधाई।\",\n","    \"क्या आप होली खेलेंगे?\",\n","    \"आपकी शिक्षा में प्रगति हो रही है।\",\n","    \"आपकी कॉलेज की पढ़ाई सराहनीय है।\",\n","    \"कॉलेज की पढ़ाई कठिन है।\",\n","    \"क्या आप उससे प्रेम करते हैं?\",\n","    \"आपकी दोस्ती सराहनीय है।\",\n","    \"आपके प्रेम में सच्चाई झलकती है।\"\n","]\n","\n","print(\"=== IndicBART model output ===\")\n","\n","# Batch inference\n","print(\"\\n🚀 Informal → Formal (Batch)\")\n","formal_outputs = batch_generate_indicbart(informal_sentences, direction=\"informal_to_formal\")\n","for informal, formal in zip(informal_sentences, formal_outputs):\n","    print(f\"Informal: {informal}\")\n","    print(f\"Formal: {formal}\\n\")\n","\n","print(\"\\n🚀 Formal → Informal (Batch)\")\n","informal_outputs = batch_generate_indicbart(formal_sentences, direction=\"formal_to_informal\")\n","for formal, informal in zip(formal_sentences, informal_outputs):\n","    print(f\"Formal: {formal}\")\n","    print(f\"Informal: {informal}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rF-_LytihyZ","executionInfo":{"status":"ok","timestamp":1745661606979,"user_tz":-330,"elapsed":141,"user":{"displayName":"Vasavi Kannuru","userId":"01253912739111961725"}},"outputId":"8eb137fb-62c1-4179-fafe-176d0a233794"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== IndicBART model output ===\n","\n","🚀 Informal → Formal (Batch)\n","Informal: खाना खा।\n","Formal: कृपया खाना खाएं।\n","\n","Informal: बैठ जा।\n","Formal: कृपया बैठ जाइए।\n","\n","Informal: जल्दी कर।\n","Formal: कृपया जल्दी करें।\n","\n","Informal: खाना मस्त था, थैंक्स!\n","Formal: यह भोजन बहुत स्वादिष्ट था।\n","\n","Informal: इस होटल की सर्विस बढ़िया है।\n","Formal: यह होटल बहुत अच्छा है।\n","\n","Informal: ऑफिस में आ जा, भाई!\n","Formal: कृपया ऑफिस में उपस्थित रहें।\n","\n","Informal: फटाफट पेपर दिखा दे।\n","Formal: कृपया मुझे पेपर की कॉपी दिखाएं।\n","\n","Informal: नई जॉब के लिए एप्लाई कर रहा क्या?\n","Formal: क्या आप इस पद के लिए आवेदन कर रहे हैं?।\n","\n","Informal: तेरी पढ़ाई तो टॉप लेवल की है।\n","Formal: आपकी पढ़ाई तो टॉप पर है।\n","\n","Informal: रिजल्ट चेक कर ले।\n","Formal: कृपया रिजल्ट चेक करें।\n","\n","Informal: शादी में आएगा ना?\n","Formal: क्या आप विवाह समारोह में शामिल होंगे?।\n","\n","Informal: टाइम पे काम कर भाई।\n","Formal: कृपया समय पर कार्य करें।\n","\n","Informal: यार मीटिंग में टाइम से आ जाना।\n","Formal: कृपया मीटिंग में समय पर उपस्थित रहें।\n","\n","Informal: तेरी तबियत ठीक चल रही है।\n","Formal: आपकी तबियत स्थिर है।\n","\n","Informal: वो मूवी देखी क्या?\n","Formal: क्या आपने वो फिल्म देखी? क्या आपने वो फिल्म देखी?।\n","\n","Informal: तेरी फेवरेट मूवी कौन सी है?\n","Formal: आपकी पसंदीदा फिल्म कौन सी है?।\n","\n","Informal: तेरे घरवालों को दिवाली मुबारक!\n","Formal: आपके परिवार को दीपावली की हार्दिक शुभकामनाएँ।\n","\n","Informal: स्कूल में सबका स्वागत है।\n","Formal: विद्यालय में सभी छात्रों का स्वागत है।\n","\n","Informal: तेरा स्कूल बहुत अच्छा है।\n","Formal: आपका वो स्कूल बहुत अच्छा है।\n","\n","Informal: तेरी पढ़ाई सही चल रही है।\n","Formal: आपकी पढ़ाई सही चल रही है।\n","\n","Informal: पेपर क्लियर किया क्या?\n","Formal: क्या आपने पेपर क्लियर किया?।\n","\n","Informal: तू उससे प्यार करता है क्या?\n","Formal: क्या आप उससे प्यार करते हैं?।\n","\n","Informal: तेरा प्यार सच्चा लगता है।\n","Formal: आपका प्रेम सच्चा प्रतीत होता है।\n","\n","\n","🚀 Formal → Informal (Batch)\n","Formal: खाना खाइए।\n","Informal: खाना खा।\n","\n","Formal: कृपया बैठ जाइए।\n","Informal: बैठ जा।\n","\n","Formal: कृपया शीघ्र करें।\n","Informal: जल्दी कर।\n","\n","Formal: भोजन अत्यंत स्वादिष्ट था, धन्यवाद।\n","Informal: खाना मस्त था, मस्त था!।\n","\n","Formal: क्या आप भोजन का स्वाद पसंद कर रहे हैं?\n","Informal: तुम खाने का स्वाद पसंद कर रहे हो क्या?।\n","\n","Formal: कृपया अपने दस्तावेज़ प्रस्तुत करें।\n","Informal: दस्तावेज़ दिखा।\n","\n","Formal: आपकी नौकरी में तरक्की हुई है।\n","Informal: तुम्हारी जॉब में ग्रोथ हुई है।\n","\n","Formal: क्या आप नई नौकरी के लिए आवेदन कर रहे हैं?\n","Informal: क्या तुम नई जॉब के लिए अप्लाई कर रहे हो?।\n","\n","Formal: आपकी शिक्षा का स्तर अत्यंत उच्च है।\n","Informal: तेरी पढ़ाई का क्वालिटी बढ़िया है।\n","\n","Formal: कृपया परीक्षा परिणाम देखें।\n","Informal: परिणाम देख।\n","\n","Formal: आपका विवाह समारोह बहुत भव्य था।\n","Informal: तुम्हारा शादी समारोह बहुत शानदार था।\n","\n","Formal: क्या आप विवाह में सम्मिलित होंगे?\n","Informal: क्या तू शादी में शामिल होगा?।\n","\n","Formal: आपके सहयोग के लिए धन्यवाद।\n","Informal: तेरी मदद के लिए धन्यवाद।\n","\n","Formal: कृपया समय पर कार्य करें।\n","Informal: टाइम पर काम कर।\n","\n","Formal: आपकी मेहनत अत्यंत सराहनीय है।\n","Informal: तेरी मेहनत बहुत सराहनीय है।\n","\n","Formal: कृपया मीटिंग में समय पर पहुंचें।\n","Informal: टाइम पर आ जाना।\n","\n","Formal: कृपया नियमित रूप से व्यायाम करें।\n","Informal: रोज़ एक्सरसाइज कर।\n","\n","Formal: क्या आपने वह फिल्म देखी है?\n","Informal: तूने वो मूवी देखी है?।\n","\n","Formal: आपकी पसंदीदा फिल्म कौन सी है?\n","Informal: तेरी फेवरेट मूवी कौन सी है?।\n","\n","Formal: त्योहार की हार्दिक शुभकामनाएँ।\n","Informal: दीवाली की मुबारकबाद!।\n","\n","Formal: आपके परिवार को दीपावली की बधाई।\n","Informal: तेरे फैमिली को दिवाली की बधाई।\n","\n","Formal: क्या आप होली खेलेंगे?\n","Informal: होली खेलेंगे क्या?।\n","\n","Formal: आपकी शिक्षा में प्रगति हो रही है।\n","Informal: तेरी एजुकेशन में ग्रोथ हो रही है।\n","\n","Formal: आपकी कॉलेज की पढ़ाई सराहनीय है।\n","Informal: तुम्हारी कॉलेज की पढ़ाई बढ़िया है।\n","\n","Formal: कॉलेज की पढ़ाई कठिन है।\n","Informal: कॉलेज में पढ़ाई मुश्किल है।\n","\n","Formal: क्या आप उससे प्रेम करते हैं?\n","Informal: तू उससे प्यार करता है क्या?।\n","\n","Formal: आपकी दोस्ती सराहनीय है।\n","Informal: तेरी दोस्ती कमाल की है।\n","\n","Formal: आपके प्रेम में सच्चाई झलकती है।\n","Informal: तेरे प्यार में सच्चाई दिखती है।\n","\n"]}]},{"cell_type":"markdown","source":["### IndicBART performance evaluation"],"metadata":{"id":"VpedxoUHcNCh"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","import pandas as pd\n","import evaluate\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# Load trained model and tokenizer\n","model_path = \"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/IndicBART_model\"\n","tokenizer = AutoTokenizer.from_pretrained(model_path, use_auth_token=True)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_path, use_auth_token=True).to(device)\n","\n","# Load test dataset\n","test_data = pd.read_csv(\"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/test.csv\")\n","# test_data = df[:500]\n","\n","# Load Evaluation Metrics\n","bleu_metric = evaluate.load(\"sacrebleu\")\n","meteor_metric = evaluate.load(\"meteor\")\n","bertscore_metric = evaluate.load(\"bertscore\")\n","\n","# Load GPT-2 for Perplexity Calculation (to measure fluency)\n","gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n","\n","# Function to generate formal sentences using T5\n","def generate_formal_sentence(informal_text):\n","    input_text = \"informal to formal: \" + informal_text\n","    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","\n","    with torch.no_grad():\n","        output_ids = model.generate(input_ids,\n","                                    max_length=128,\n","                                    num_beams=5,\n","                                    repetition_penalty=2.0)  # Better output quality\n","\n","    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","# Function to calculate Perplexity (Lower = Better Fluency)\n","def calculate_perplexity(sentence):\n","    inputs = gpt2_tokenizer(sentence, return_tensors=\"pt\").input_ids.to(device)\n","    with torch.no_grad():\n","        loss = gpt2_model(inputs, labels=inputs).loss\n","    return torch.exp(loss).item()\n","\n","# Evaluate model\n","correct_predictions = 0\n","total_samples = len(test_data)\n","predictions, references, perplexities = [], [], []\n","\n","for i, row in test_data.iterrows():\n","    informal = row[\"informal\"]\n","    formal = row[\"formal\"]\n","\n","    predicted_formal = generate_formal_sentence(informal)\n","\n","    predictions.append(predicted_formal)\n","    references.append([formal])  # BLEU expects a list of references\n","    perplexities.append(calculate_perplexity(predicted_formal))  # Fluency score\n","\n","    if predicted_formal.strip() == formal.strip():\n","        correct_predictions += 1\n","\n","# Calculate accuracy\n","accuracy = correct_predictions / total_samples * 100\n","\n","# Compute automatic evaluation metrics\n","bleu_score = bleu_metric.compute(predictions=predictions, references=references)[\"score\"]\n","bertscore_results = bertscore_metric.compute(predictions=predictions, references=references, lang=\"hi\")\n","avg_perplexity = sum(perplexities) / len(perplexities)  # Average perplexity\n","\n","# Print Results\n","print(\"\\n===== IndicBART Model Evaluation Results =====\")\n","print(f\"🔹 BLEU Score: {bleu_score:.2f}\")\n","print(f\"🔹 BERTScore Precision: {sum(bertscore_results['precision']) / len(bertscore_results['precision']):.2f}\")\n","print(f\"🔹 BERTScore Recall: {sum(bertscore_results['recall']) / len(bertscore_results['recall']):.2f}\")\n","print(f\"🔹 BERTScore F1: {sum(bertscore_results['f1']) / len(bertscore_results['f1']):.2f}\")\n","print(f\"🔹 Perplexity (Lower = Better Fluency): {avg_perplexity:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TkUH2BFnZNmk","executionInfo":{"status":"ok","timestamp":1745659291154,"user_tz":-330,"elapsed":65,"user":{"displayName":"Vasavi Kannuru","userId":"01253912739111961725"}},"outputId":"60d53f16-abd2-4a55-f231-21760414bb98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","\n","===== IndicBART Model Evaluation Results =====\n","🔹 BLEU Score: 17.84\n","🔹 BERTScore Precision: 0.81\n","🔹 BERTScore Recall: 0.82\n","🔹 BERTScore F1: 0.81\n","🔹 Perplexity (Lower = Better Fluency): 5.36\n"]}]},{"cell_type":"markdown","source":["# Ensemble Model(mT5+IndicBART)"],"metadata":{"id":"LNYiQU9Jcfo-"}},{"cell_type":"code","source":["import torch\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","# Setup\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load mT5 model and tokenizer\n","mt5_tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-base\")\n","mt5_model = T5ForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/mt5_model\").to(device)\n","mt5_model.eval()\n","\n","# Load IndicBART model and tokenizer\n","indic_tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indicbart\", use_fast=False)\n","indic_model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/IndicBART_model\").to(device)\n","indic_model.eval()\n","\n","# Ensemble inference function using prompted format\n","def ensemble_generate(prompt_text):\n","    # --- mT5 generation ---\n","    mt5_inputs = mt5_tokenizer(prompt_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","    with torch.no_grad():\n","        mt5_output_ids = mt5_model.generate(\n","            input_ids=mt5_inputs[\"input_ids\"],\n","            attention_mask=mt5_inputs[\"attention_mask\"],\n","            max_length=128,\n","            num_beams=5,\n","            early_stopping=True,\n","        )\n","    mt5_output = mt5_tokenizer.decode(mt5_output_ids[0], skip_special_tokens=True)\n","\n","    # --- IndicBART generation ---\n","    indic_inputs = indic_tokenizer(prompt_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","    with torch.no_grad():\n","        indic_output_ids = indic_model.generate(\n","            input_ids=indic_inputs[\"input_ids\"],\n","            attention_mask=indic_inputs[\"attention_mask\"],\n","            max_length=128,\n","            num_beams=5,\n","            early_stopping=True,\n","        )\n","    indic_output = indic_tokenizer.decode(indic_output_ids[0], skip_special_tokens=True)\n","\n","    # Return longer output (or use mT5 by default if equal)\n","    return mt5_output if len(mt5_output) >= len(indic_output) else indic_output\n","\n","# Wrapper like your previous code\n","def generate_sentence_ensemble(input_text, direction=\"informal_to_formal\"):\n","    \"\"\"\n","    Uses both mT5 and IndicBART to generate sentence in specified direction.\n","    \"\"\"\n","    prompt = f\"{'informal to formal' if direction == 'informal_to_formal' else 'formal to informal'}: {input_text}\"\n","    return ensemble_generate(prompt)\n","\n","# Test Examples\n","print(\"\\n🚀 Testing Ensemble Model\")\n","print(\"Informal → Formal:\", generate_sentence_ensemble(\"तू कहाँ जा रहा है?\", direction=\"informal_to_formal\"))\n","print(\"Formal → Informal:\", generate_sentence_ensemble(\"आप कहाँ जा रहे हैं?\", direction=\"formal_to_informal\"))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ehl4_itkZuP0","executionInfo":{"status":"ok","timestamp":1745677062483,"user_tz":-330,"elapsed":47,"user":{"displayName":"Vasavi Kannuru","userId":"01253912739111961725"}},"outputId":"c51306bb-d13b-40a3-f2d3-dbeb884a3df2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing Ensemble Model\n","Informal → Formal: आप कहाँ जा रहे हैं?\n","Formal → Informal: तुम कहाँ जा रहे हो?\n"]}]},{"cell_type":"markdown","source":["###Ensemble Model inference"],"metadata":{"id":"TWlxweAU1-Tq"}},{"cell_type":"code","source":["import torch\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","# Setup device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load mT5 model and tokenizer\n","mt5_tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-base\")\n","mt5_model = T5ForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/mt5_model\").to(device)\n","mt5_model.eval()\n","\n","# Load IndicBART model and tokenizer\n","indic_tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indicbart\", use_fast=False)\n","indic_model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/IndicBART_model\").to(device)\n","indic_model.eval()\n","\n","# Helper function: Clean output to only keep first sentence\n","def clean_first_sentence(text):\n","    # Split on '।' and pick the first part\n","    first_sentence = text.split('।')[0].strip()\n","    if first_sentence:\n","        first_sentence += '।'\n","    return first_sentence\n","\n","# Generate output from ensemble (choose longer output, then clean)\n","def ensemble_generate(prompt_text):\n","    # --- mT5\n","    mt5_inputs = mt5_tokenizer(prompt_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","    with torch.no_grad():\n","        mt5_output_ids = mt5_model.generate(\n","            input_ids=mt5_inputs[\"input_ids\"],\n","            attention_mask=mt5_inputs[\"attention_mask\"],\n","            max_length=128,\n","            num_beams=5,\n","            early_stopping=True,\n","        )\n","    mt5_output = mt5_tokenizer.decode(mt5_output_ids[0], skip_special_tokens=True)\n","    mt5_output = clean_first_sentence(mt5_output)  # 🛠 clean mT5 output\n","\n","    # --- IndicBART\n","    indic_inputs = indic_tokenizer(prompt_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n","    with torch.no_grad():\n","        indic_output_ids = indic_model.generate(\n","            input_ids=indic_inputs[\"input_ids\"],\n","            attention_mask=indic_inputs[\"attention_mask\"],\n","            max_length=128,\n","            num_beams=5,\n","            early_stopping=True,\n","        )\n","    indic_output = indic_tokenizer.decode(indic_output_ids[0], skip_special_tokens=True)\n","    indic_output = clean_first_sentence(indic_output)  # 🛠 clean IndicBART output\n","\n","    # Return longer output (or mT5 default if equal)\n","    return mt5_output if len(mt5_output) >= len(indic_output) else indic_output\n","\n","# Batch wrapper for ensemble model\n","def batch_generate_ensemble(sentences, direction=\"informal_to_formal\"):\n","    \"\"\"\n","    Runs ensemble inference for a batch of sentences in the specified direction.\n","    \"\"\"\n","    outputs = []\n","    for sentence in sentences:\n","        prompt = f\"{'informal to formal' if direction == 'informal_to_formal' else 'formal to informal'}: {sentence}\"\n","        generated = ensemble_generate(prompt)\n","        outputs.append(generated)\n","    return outputs\n","\n","# Example testing with multiple sentences\n","informal_sentences = [\n","    \"खाना खा।\",\n","    \"बैठ जा।\",\n","    \"जल्दी कर।\",\n","    \"इस होटल की सर्विस बढ़िया है।\",\n","    \"ऑफिस में आ जा, भाई!\",\n","    \"फटाफट पेपर दिखा दे।\",\n","    \"नई जॉब के लिए एप्लाई कर रहा क्या?\",\n","    \"तेरी पढ़ाई तो टॉप लेवल की है।\",\n","    \"रिजल्ट चेक कर ले।\",\n","    \"शादी में आएगा ना?\",\n","    \"टाइम पे काम कर भाई।\",\n","    \"यार मीटिंग में टाइम से आ जाना।\",\n","    \"तेरी तबियत ठीक चल रही है।\",\n","    \"वो मूवी देखी क्या?\",\n","    \"तेरी फेवरेट मूवी कौन सी है?\",\n","    \"तेरे घरवालों को दिवाली मुबारक!\",\n","    \"तेरा स्कूल बहुत अच्छा है।\",\n","    \"पेपर क्लियर किया क्या?\",\n","    \"तू उससे प्यार करता है क्या?\",\n","    \"तेरा प्यार सच्चा लगता है।\"\n","]\n","\n","formal_sentences = [\n","    \"खाना खाइए।\",\n","    \"कृपया बैठ जाइए।\",\n","    \"कृपया शीघ्र करें।\",\n","    \"भोजन अत्यंत स्वादिष्ट था, धन्यवाद।\",\n","    \"क्या आप भोजन का स्वाद पसंद कर रहे हैं?\",\n","    \"कृपया अपने दस्तावेज़ प्रस्तुत करें।\",\n","    \"आपकी नौकरी में तरक्की हुई है।\",\n","    \"क्या आप नई नौकरी के लिए आवेदन कर रहे हैं?\",\n","    \"आपकी शिक्षा का स्तर अत्यंत उच्च है।\",\n","    \"कृपया परीक्षा परिणाम देखें।\",\n","    \"आपका विवाह समारोह बहुत भव्य था।\",\n","    \"क्या आप विवाह में सम्मिलित होंगे?\",\n","    \"आपके सहयोग के लिए धन्यवाद।\",\n","    \"कृपया समय पर कार्य करें।\",\n","    \"आपकी मेहनत अत्यंत सराहनीय है।\",\n","    \"कृपया मीटिंग में समय पर पहुंचें।\",\n","    \"कृपया नियमित रूप से व्यायाम करें।\",\n","    \"क्या आपने वह फिल्म देखी है?\",\n","    \"आपकी पसंदीदा फिल्म कौन सी है?\",\n","    \"त्योहार की हार्दिक शुभकामनाएँ।\",\n","    \"आपके परिवार को दीपावली की बधाई।\",\n","    \"क्या आप होली खेलेंगे?\",\n","    \"कॉलेज की पढ़ाई कठिन है।\",\n","    \"क्या आप उससे प्रेम करते हैं?\",\n","    \"आपकी दोस्ती सराहनीय है।\",\n","    \"आपके प्रेम में सच्चाई झलकती है।\"\n","]\n","\n","print(\"=== Ensemble Model (mT5 + IndicBART) output ===\")\n","# Run ensemble test\n","print(\"\\n🚀 Ensemble Informal → Formal\")\n","formal_outputs = batch_generate_ensemble(informal_sentences, direction=\"informal_to_formal\")\n","for informal, formal in zip(informal_sentences, formal_outputs):\n","    print(f\"Informal: {informal}\")\n","    print(f\"Formal: {formal}\\n\")\n","\n","print(\"\\n🚀 Ensemble Formal → Informal\")\n","informal_outputs = batch_generate_ensemble(formal_sentences, direction=\"formal_to_informal\")\n","for formal, informal in zip(formal_sentences, informal_outputs):\n","    print(f\"Formal: {formal}\")\n","    print(f\"Informal: {informal}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I9HbZm8sde5t","executionInfo":{"status":"ok","timestamp":1745683412450,"user_tz":-330,"elapsed":245,"user":{"displayName":"Vasavi Kannuru","userId":"01253912739111961725"}},"outputId":"4bbc5bfc-bf39-47cd-996a-026493f62c02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Ensemble Model (mT5 + IndicBART) output ===\n","\n","🚀 Ensemble Informal → Formal\n","Informal: खाना खा।\n","Formal: कृपया खाना खाइए।\n","\n","Informal: बैठ जा।\n","Formal: कृपया बैठ जाइए।\n","\n","Informal: जल्दी कर।\n","Formal: कृपया जल्दी करें।\n","\n","Informal: इस होटल की सर्विस बढ़िया है।\n","Formal: इस होटल की सर्विस बहुत सराहनीय है।\n","\n","Informal: ऑफिस में आ जा, भाई!\n","Formal: कृपया ऑफिस में उपस्थित रहें।\n","\n","Informal: फटाफट पेपर दिखा दे।\n","Formal: कृपया मुझे फटाफट पेपर दिखा दीजिए।\n","\n","Informal: नई जॉब के लिए एप्लाई कर रहा क्या?\n","Formal: क्या आप नई जॉब के लिए एप्लाई कर रहे हैं?।\n","\n","Informal: तेरी पढ़ाई तो टॉप लेवल की है।\n","Formal: आपकी पढ़ाई तो टॉप लेवल की है।\n","\n","Informal: रिजल्ट चेक कर ले।\n","Formal: कृपया रिजल्ट चेक करें।\n","\n","Informal: शादी में आएगा ना?\n","Formal: क्या आप विवाह समारोह में शामिल होंगे?।\n","\n","Informal: टाइम पे काम कर भाई।\n","Formal: कृपया समय पर कार्य करें।\n","\n","Informal: यार मीटिंग में टाइम से आ जाना।\n","Formal: कृपया मीटिंग में समय पर उपस्थित रहें।\n","\n","Informal: तेरी तबियत ठीक चल रही है।\n","Formal: आपकी तबियत ठीक चल रही है।\n","\n","Informal: वो मूवी देखी क्या?\n","Formal: क्या आपने वो फिल्म देखी? क्या आपने वो फिल्म देखी?।\n","\n","Informal: तेरी फेवरेट मूवी कौन सी है?\n","Formal: आपकी पसंदीदा फिल्म कौन सी है?।\n","\n","Informal: तेरे घरवालों को दिवाली मुबारक!\n","Formal: आपके परिवार को दीपावली की हार्दिक शुभकामनाएँ।\n","\n","Informal: तेरा स्कूल बहुत अच्छा है।\n","Formal: आपका वो स्कूल बहुत अच्छा है।\n","\n","Informal: पेपर क्लियर किया क्या?\n","Formal: क्या आपने पेपर क्लियर किया?।\n","\n","Informal: तू उससे प्यार करता है क्या?\n","Formal: क्या आप वोसे प्यार करते हैं?।\n","\n","Informal: तेरा प्यार सच्चा लगता है।\n","Formal: आपका प्रेम सच्चा प्रतीत होता है।\n","\n","Informal: खाना मस्त था, थैंक्स!\n","Formal: यह भोजन बहुत स्वादिष्ट था।\n","\n","Informal: स्कूल में सबका स्वागत है।\n","Formal: विद्यालय में छात्रों के लिए सबका स्वागत है।\n","\n","Informal: तेरी पढ़ाई सही चल रही है।\n","Formal: आपकी तेरी पढ़ाई बहुत सराहनीय है।\n","\n","\n","🚀 Ensemble Formal → Informal\n","Formal: खाना खाइए।\n","Informal: खाना खाइए।\n","\n","Formal: कृपया बैठ जाइए।\n","Informal: बैठ जा।\n","\n","Formal: कृपया शीघ्र करें।\n","Informal: शीघ्र कर।\n","\n","Formal: भोजन अत्यंत स्वादिष्ट था, धन्यवाद।\n","Informal: भाई, भोजन बहुत अच्छा था।\n","\n","Formal: क्या आप भोजन का स्वाद पसंद कर रहे हैं?\n","Informal: तुम खाने का स्वाद पसंद कर रहे हो क्या?।\n","\n","Formal: कृपया अपने दस्तावेज़ प्रस्तुत करें।\n","Informal: अपने दस्तावेज़ प्रस्तुत कर।\n","\n","Formal: आपकी नौकरी में तरक्की हुई है।\n","Informal: तुम्हारी जॉब में ग्रोथ हुई है।\n","\n","Formal: क्या आप नई नौकरी के लिए आवेदन कर रहे हैं?\n","Informal: क्या तुम नई जॉब के लिए अप्लाई कर रहे हो?।\n","\n","Formal: आपकी शिक्षा का स्तर अत्यंत उच्च है।\n","Informal: तेरी शिक्षा का स्तर बहुत बढ़िया है।\n","\n","Formal: कृपया परीक्षा परिणाम देखें।\n","Informal: परीक्षा परिणाम देख।\n","\n","Formal: आपका विवाह समारोह बहुत भव्य था।\n","Informal: तुम्हारा शादी समारोह बहुत शानदार था।\n","\n","Formal: क्या आप विवाह में सम्मिलित होंगे?\n","Informal: क्या तू विवाह में हिस्सा लेगा?।\n","\n","Formal: आपके सहयोग के लिए धन्यवाद।\n","Informal: तेरे सहयोग के लिए धन्यवाद।\n","\n","Formal: कृपया समय पर कार्य करें।\n","Informal: टाइम पर काम कर।\n","\n","Formal: आपकी मेहनत अत्यंत सराहनीय है।\n","Informal: तेरी मेहनत बहुत सराहनीय है।\n","\n","Formal: कृपया मीटिंग में समय पर पहुंचें।\n","Informal: भाई, मीटिंग में टाइम पर पहुंच।\n","\n","Formal: कृपया नियमित रूप से व्यायाम करें।\n","Informal: नियमित रूप से व्यायाम कर।\n","\n","Formal: क्या आपने वह फिल्म देखी है?\n","Informal: क्या तूने उस फिल्म देखी है?।\n","\n","Formal: आपकी पसंदीदा फिल्म कौन सी है?\n","Informal: तेरी फेवरेट फिल्म कौन सी है?।\n","\n","Formal: त्योहार की हार्दिक शुभकामनाएँ।\n","Informal: त्योहार की शुभकामनाएँ।\n","\n","Formal: आपके परिवार को दीपावली की बधाई।\n","Informal: तेरे परिवार को दीपावली की बधाई।\n","\n","Formal: क्या आप होली खेलेंगे?\n","Informal: होली खेलेंगे क्या?।\n","\n","Formal: कॉलेज की पढ़ाई कठिन है।\n","Informal: कॉलेज में पढ़ाई मुश्किल है।\n","\n","Formal: क्या आप उससे प्रेम करते हैं?\n","Informal: क्या तू उससे प्यार करता है?।\n","\n","Formal: आपकी दोस्ती सराहनीय है।\n","Informal: तेरी दोस्ती बहुत बढ़िया है।\n","\n","Formal: आपके प्रेम में सच्चाई झलकती है।\n","Informal: तेरे प्यार में सच्चाई झलकती है।\n"]}]},{"cell_type":"markdown","source":["## Ensemble performance evaluation"],"metadata":{"id":"K263bcVs2QyS"}},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer, AutoModelForSeq2SeqLM\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import evaluate\n","\n","# Setup\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load models and tokenizers\n","mt5_tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-base\")\n","mt5_model = T5ForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/mt5_model\").to(device)\n","\n","indic_tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indicbart\", use_fast=False)\n","indic_model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/Hindi_Formality_Style_Transfer/TST/IndicBART_model\").to(device)\n","\n","# GPT-2 for Perplexity\n","gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n","\n","# Evaluation metrics\n","bleu = evaluate.load(\"sacrebleu\")\n","rouge = evaluate.load(\"rouge\")\n","bertscore = evaluate.load(\"bertscore\")\n","\n","# Ensemble Inference Function\n","def ensemble_generate(text, max_length=128):\n","    # Prepare inputs\n","    mt5_input = mt5_tokenizer(\"informal to formal: \" + text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","    indic_input = indic_tokenizer(\"informal to formal: \" + text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","\n","    # Get encoder outputs\n","    with torch.no_grad():\n","        mt5_output = mt5_model.generate(\n","            input_ids=mt5_input[\"input_ids\"],\n","            attention_mask=mt5_input[\"attention_mask\"],\n","            max_length=max_length,\n","            num_beams=5,\n","            early_stopping=True\n","        )\n","\n","        indic_output = indic_model.generate(\n","            input_ids=indic_input[\"input_ids\"],\n","            attention_mask=indic_input[\"attention_mask\"],\n","            max_length=max_length,\n","            num_beams=5,\n","            early_stopping=True\n","        )\n","\n","    # Decode outputs\n","    mt5_decoded = mt5_tokenizer.decode(mt5_output[0], skip_special_tokens=True)\n","    indic_decoded = indic_tokenizer.decode(indic_output[0], skip_special_tokens=True)\n","\n","    # Simple heuristic: pick the more fluent sentence (lower perplexity)\n","    mt5_ppl = calculate_perplexity(mt5_decoded)\n","    indic_ppl = calculate_perplexity(indic_decoded)\n","\n","    return mt5_decoded if mt5_ppl < indic_ppl else indic_decoded\n","\n","# Perplexity calculation\n","def calculate_perplexity(sentence):\n","    inputs = gpt2_tokenizer(sentence, return_tensors=\"pt\").input_ids.to(device)\n","    with torch.no_grad():\n","        loss = gpt2_model(inputs, labels=inputs).loss\n","    return torch.exp(loss).item()\n","\n","# Load test set\n","test_data = pd.read_csv(\"/content/drive/MyDrive/TST/test.csv\")\n","# test_data = df[:500]\n","\n","# Run evaluation\n","predictions, references, perplexities = [], [], []\n","correct = 0\n","\n","for _, row in test_data.iterrows():\n","    informal = row[\"informal\"]\n","    formal = row[\"formal\"]\n","\n","    pred = ensemble_generate(informal)\n","    ppl = calculate_perplexity(pred)\n","\n","    predictions.append(pred)\n","    references.append([formal])\n","    perplexities.append(ppl)\n","\n","    if pred.strip() == formal.strip():\n","        correct += 1\n","\n","# Compute metrics\n","accuracy = correct / len(test_data) * 100\n","bleu_score = bleu.compute(predictions=predictions, references=references)[\"score\"]\n","rouge_scores = rouge.compute(predictions=predictions, references=references)\n","berts = bertscore.compute(predictions=predictions, references=[r[0] for r in references], lang=\"hi\")\n","avg_ppl = sum(perplexities) / len(perplexities)\n","\n","# Print results\n","print(\"\\n===== Ensemble Model (mT5 + IndicBART) Evaluation Results =====\")\n","print(f\"🔹 Accuracy: {accuracy:.2f}%\")\n","print(f\"🔹 BLEU Score: {bleu_score:.2f}\")\n","print(f\"🔹 ROUGE: {rouge_scores}\")\n","print(f\"🔹 BERTScore Precision: {sum(berts['precision']) / len(berts['precision']):.2f}\")\n","print(f\"🔹 BERTScore Recall: {sum(berts['recall']) / len(berts['recall']):.2f}\")\n","print(f\"🔹 BERTScore F1: {sum(berts['f1']) / len(berts['f1']):.2f}\")\n","print(f\"🔹 Average Perplexity: {avg_ppl:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9g9ZalBO1vNy","executionInfo":{"status":"ok","timestamp":1745685317730,"user_tz":-330,"elapsed":19,"user":{"displayName":"Vasavi Kannuru","userId":"01253912739111961725"}},"outputId":"16cb65bc-049a-40d7-e2ea-0b4165224094"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["===== Ensemble Model (mT5 + IndicBART) Evaluation Results =====\n","🔹 Accuracy: 7.51%\n","🔹 BLEU Score: 21.65\n","🔹 ROUGE: {'rouge1': np.float64(0.0), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.0), 'rougeLsum': np.float64(0.0)}\n","🔹 BERTScore Precision: 0.84\n","🔹 BERTScore Recall: 0.84\n","🔹 BERTScore F1: 0.84\n","🔹 Average Perplexity: 6.20\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"494if2g29Aau"},"execution_count":null,"outputs":[]}]}